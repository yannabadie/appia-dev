# üìö R√©f√©rence API JARVYS_DEV

*G√©n√©r√©e automatiquement le 10/07/2025 √† 18:20*

## üîß Modules Principaux

### `jarvys_dev.langgraph_loop`

La boucle principale bas√©e sur LangGraph qui orchestre le comportement autonome.

**Fonctions disponibles:**


```python
from jarvys_dev.langgraph_loop import run_loop

# Ex√©cuter 1 cycle autonome
state = run_loop(steps=1)
print(state)
```

### `jarvys_dev.multi_model_router`

Routeur intelligent pour les mod√®les LLM avec fallback automatique.

```python
from jarvys_dev.multi_model_router import MultiModelRouter

router = MultiModelRouter()
response = router.generate("Explain this code", task_type="reasoning")
```

**Types de t√¢ches support√©s:**
- `reasoning`: Raisonnement logique (OpenAI ‚Üí Anthropic ‚Üí Gemini)
- `multimodal`: Traitement multimodal (Gemini ‚Üí OpenAI ‚Üí Anthropic)
- `creativity`: T√¢ches cr√©atives (OpenAI ‚Üí Anthropic ‚Üí Gemini)

## üõ†Ô∏è Outils (Tools)

### `jarvys_dev.tools.github_tools`
GitHub helpers.

Secrets n√©cessaires¬†: GH_TOKEN, GH_REPO

**Fonctions disponibles:**

### `jarvys_dev.tools.memory`
No description available

**Fonctions disponibles:**


## üîÑ √âtats de la Boucle

```python
class LoopState(TypedDict):
    observation: str              # Observation actuelle
    plan: str                    # Plan d'action g√©n√©r√©
    action_url: str              # URL de l'action effectu√©e
    reflected: bool              # √âtat de la r√©flexion
    waiting_for_human_review: bool  # Escalade vers humain
```

## üéõÔ∏è Configuration

### Variables d'environnement

| Variable | Requis | Description |
|----------|--------|-------------|
| `OPENAI_API_KEY` | ‚úÖ | Cl√© API OpenAI |
| `GH_TOKEN` | ‚úÖ | Token GitHub |
| `GH_REPO` | ‚úÖ | Repository GitHub (owner/repo) |
| `SUPABASE_URL` | ‚úÖ | URL Supabase |
| `SUPABASE_KEY` | ‚úÖ | Cl√© Supabase |
| `GEMINI_API_KEY` | ‚úÖ | Cl√© Google AI |
| `GCP_SA_JSON` | ‚úÖ | Service Account GCP (JSON) |
| `ANTHROPIC_API_KEY` | ‚ùå | Cl√© Anthropic (optionnel via GitHub Copilot) |
| `CONFIDENCE_SCORE` | ‚ùå | Score de confiance (d√©faut: 1.0) |

### Configuration des mod√®les

Le fichier `src/jarvys_dev/model_config.json` est mis √† jour automatiquement par le model watcher :

```json
{
  "openai": "whisper-1",
  "anthropic": "claude-4",
  "gemini": "models/text-embedding-004"
}
```

## üîå Int√©grations

### Github
- **Fonctionnalit√©s**: Issues, PRs, Projects, GraphQL
- **Secrets requis**: GH_TOKEN, GH_REPO

### Supabase
- **Fonctionnalit√©s**: Vector DB, RLS, SQL functions
- **Secrets requis**: SUPABASE_URL, SUPABASE_KEY


### Serveur MCP
- **Port**: 54321
- **Type**: Model Context Protocol
- **Endpoints**: /v1/tool-metadata, /v1/tool-invocations/ask_llm


## üìä Monitoring

### Benchmarking automatique
```python
router = MultiModelRouter()
response = router.generate("test")

# Acc√®s aux m√©triques  
for benchmark in router.benchmarks:
    print("Model:", benchmark.model)
    print("Latency:", benchmark.latency)
    print("Cost proxy:", benchmark.cost)
```

### Logs s√©curis√©s
Les secrets sont automatiquement masqu√©s dans les logs gr√¢ce au `_SecretFilter`.

---

*Cette documentation API est g√©n√©r√©e automatiquement depuis le code source.*
