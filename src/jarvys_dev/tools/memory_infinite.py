"""
Outils de gestion de la m√©moire infinie partag√©e entre JARVYS_DEV et JARVYS_AI.
Utilise Supabase comme base vectorielle pour persistance et recherche s√©mantique.
"""

import hashlib
import logging
import os
from datetime import datetime
from typing import Any, Dict, List, Optional

import openai

from supabase import Client, create_client

logger = logging.getLogger(__name__)


class JarvysInfiniteMemory:
    """Gestionnaire de m√©moire infinie partag√©e pour l'√©cosyst√®me JARVYS."""

    def __init__(
        self, agent_name: str = "JARVYS_DEV", user_context: str = "default"
    ):
        self.agent_name = agent_name
        self.user_context = user_context
        self.supabase: Optional[Client] = None
        self.openai_client = None

        # Initialisation Supabase
        supabase_url = os.getenv("SUPABASE_URL")
        supabase_key = os.getenv("SUPABASE_KEY")

        if supabase_url and supabase_key:
            try:
                self.supabase = create_client(supabase_url, supabase_key)
                logger.info(
                    f"‚úÖ M√©moire infinie initialis√©e pour {agent_name}"
                )
            except Exception as e:
                logger.error(f"‚ùå Erreur connexion Supabase: {e}")

        # Initialisation OpenAI pour embeddings
        openai_key = os.getenv("OPENAI_API_KEY")
        if openai_key:
            self.openai_client = openai.OpenAI(api_key=openai_key)

    def memorize(
        self,
        content: str,
        memory_type: str = "experience",
        importance_score: float = 0.5,
        tags: Optional[List[str]] = None,
        metadata: Optional[Dict[str, Any]] = None,
    ) -> bool:
        """
        M√©morise une information dans la m√©moire infinie.

        Args:
            content: Le contenu √† m√©moriser
            memory_type: Type de m√©moire ('conversation', 'preference', 'knowledge', 'experience')
            importance_score: Score d'importance (0.0 √† 1.0)
            tags: Tags pour cat√©goriser
            metadata: M√©tadonn√©es additionnelles

        Returns:
            True si succ√®s, False sinon
        """
        if not self.supabase or not self.openai_client:
            logger.warning(
                "M√©moire non disponible (Supabase ou OpenAI manquant)"
            )
            return False

        try:
            # G√©n√©rer l'embedding
            embedding = self._generate_embedding(content)
            if not embedding:
                return False

            # Pr√©parer les donn√©es
            memory_data = {
                "content": content,
                "agent_source": self.agent_name,
                "memory_type": memory_type,
                "user_context": self.user_context,
                "importance_score": importance_score,
                "tags": tags or [],
                "metadata": metadata or {},
                "embedding": embedding,
            }

            # Ins√©rer dans Supabase
            _result = (
                self.supabase.table("jarvys_memory")
                .insert(memory_data)
                .execute()
            )

            if result.data:
                logger.info(f"üíæ M√©moire sauvegard√©e: {content[:50]}...")
                return True
            else:
                logger.error(f"‚ùå √âchec sauvegarde m√©moire: {result}")
                return False

        except Exception as e:
            logger.error(f"‚ùå Erreur m√©morisation: {e}")
            return False

    def recall(
        self,
        query: str,
        memory_types: Optional[List[str]] = None,
        min_importance: float = 0.0,
        limit: int = 10,
    ) -> List[Dict[str, Any]]:
        """
        Recherche dans la m√©moire infinie.

        Args:
            query: Requ√™te de recherche
            memory_types: Types de m√©moire √† rechercher
            min_importance: Score d'importance minimum
            limit: Nombre maximum de r√©sultats

        Returns:
            Liste des souvenirs trouv√©s
        """
        if not self.supabase or not self.openai_client:
            logger.warning("M√©moire non disponible pour la recherche")
            return []

        try:
            # G√©n√©rer l'embedding de la requ√™te
            query_embedding = self._generate_embedding(query)
            if not query_embedding:
                return []

            # Construire la requ√™te Supabase
            query_builder = (
                self.supabase.table("jarvys_memory")
                .select("*")
                .eq("user_context", self.user_context)
                .gte("importance_score", min_importance)
                .order("created_at", desc=True)
                .limit(limit)
            )

            # Filtrer par type de m√©moire si sp√©cifi√©
            if memory_types:
                query_builder = query_builder.in_("memory_type", memory_types)

            _result = query_builder.execute()

            if result.data:
                # Calculer la similarit√© et trier
                memories = []
                for memory in result.data:
                    if memory.get("embedding"):
                        similarity = self._calculate_similarity(
                            query_embedding, memory["embedding"]
                        )
                        memory["similarity"] = similarity
                        memories.append(memory)

                # Trier par similarit√© d√©croissante
                memories.sort(key=lambda x: x["similarity"], reverse=True)

                logger.info(
                    f"üß† {len(memories)} souvenirs trouv√©s pour:"
                    "{query[:30]}..."
                )
                return memories[:limit]

            return []

        except Exception as e:
            logger.error(f"‚ùå Erreur recherche m√©moire: {e}")
            return []

    def get_memory_stats(self) -> Dict[str, Any]:
        """Retourne des statistiques sur la m√©moire."""
        if not self.supabase:
            return {"error": "M√©moire non disponible"}

        try:
            # Nombre total de souvenirs
            total_result = (
                self.supabase.table("jarvys_memory")
                .select("id", count="exact")
                .eq("user_context", self.user_context)
                .execute()
            )

            # Souvenirs par agent
            agents_result = (
                self.supabase.table("jarvys_memory")
                .select("agent_source", count="exact")
                .eq("user_context", self.user_context)
                .execute()
            )

            # Souvenirs par type
            types_result = (
                self.supabase.table("jarvys_memory")
                .select("memory_type", count="exact")
                .eq("user_context", self.user_context)
                .execute()
            )

            return {
                "total_memories": total_result.count or 0,
                "by_agent": {
                    item["agent_source"]: item["count"]
                    for item in agents_result.data or []
                },
                "by_type": {
                    item["memory_type"]: item["count"]
                    for item in types_result.data or []
                },
                "user_context": self.user_context,
                "last_updated": datetime.now().isoformat(),
            }

        except Exception as e:
            logger.error(f"‚ùå Erreur stats m√©moire: {e}")
            return {"error": str(e)}

    def _generate_embedding(self, text: str) -> Optional[List[float]]:
        """G√©n√®re un embedding pour le texte."""
        if not self.openai_client:
            return None

        try:
            _response = self.openai_client.embeddings.create(
                model="text-embedding-3-small", input=text
            )
            return response.data[0].embedding

        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration embedding: {e}")
            return None

    def _calculate_similarity(
        self, embedding1: List[float], embedding2: List[float]
    ) -> float:
        """Calcule la similarit√© cosinus entre deux embeddings."""
        try:
            import numpy as np

            # Normaliser les vecteurs
            a = np.array(embedding1)
            b = np.array(embedding2)

            # Similarit√© cosinus
            similarity = np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))
            return float(similarity)

        except Exception:
            return 0.0

    def log_interaction(
        self, interaction_type: str, content: str, success: bool = True
    ):
        """Log une interaction pour le monitoring."""
        if not self.supabase:
            return

        try:
            self.supabase.table("jarvys_metrics").insert(
                {
                    "agent_type": self.agent_name,
                    "event_type": "memory_operation",
                    "service": "supabase",
                    "success": success,
                    "metadata": {
                        "interaction_type": interaction_type,
                        "content_hash": hashlib.md5(
                            content.encode()
                        ).hexdigest()[:8],
                    },
                    "user_context": self.user_context,
                }
            ).execute()

        except Exception as e:
            logger.error(f"‚ùå Erreur log interaction: {e}")


# Instance globale pour JARVYS_DEV
_memory_instance = None


def get_memory(
    agent_name: str = "JARVYS_DEV", user_context: str = "default"
) -> JarvysInfiniteMemory:
    """R√©cup√®re l'instance de m√©moire (singleton par agent/user)."""
    global _memory_instance

    if _memory_instance is None or _memory_instance.agent_name != agent_name:
        _memory_instance = JarvysInfiniteMemory(agent_name, user_context)

    return _memory_instance


# Fonctions de compatibilit√© avec l'ancien code
def memory_search(
    query: str, user_context: str = "default"
) -> List[Dict[str, Any]]:
    """Recherche dans la m√©moire (fonction de compatibilit√©)."""
    memory = get_memory("JARVYS_DEV", user_context)
    return memory.recall(query)


def upsert_embedding(content: str, user_context: str = "default") -> bool:
    """M√©morise du contenu (fonction de compatibilit√©)."""
    memory = get_memory("JARVYS_DEV", user_context)
    return memory.memorize(content, memory_type="knowledge")


def get_memory_context(user_context: str = "default") -> str:
    """R√©cup√®re le contexte de m√©moire r√©cent pour un utilisateur."""
    memory = get_memory("JARVYS_DEV", user_context)
    recent_memories = memory.recall(
        "contexte r√©cent conversation",
        memory_types=["conversation", "preference"],
        limit=5,
    )

    if recent_memories:
        context_parts = []
        for mem in recent_memories:
            context_parts.append(f"{mem['memory_type']}: {mem['content']}")
        return "\n".join(context_parts)

    return "Aucun contexte de m√©moire disponible."


if __name__ == "__main__":
    # Test de la m√©moire infinie
    memory = get_memory("JARVYS_DEV", "test_user")

    # Test m√©morisation
    success = memory.memorize(
        "L'utilisateur pr√©f√®re les solutions simples et √©pur√©es",
        memory_type="preference",
        importance_score=0.8,
        tags=["preferences", "ui", "design"],
    )
    print(f"M√©morisation: {'‚úÖ' if success else '‚ùå'}")

    # Test recherche
    results = memory.recall("pr√©f√©rences utilisateur", limit=3)
    print(f"Recherche: {len(results)} r√©sultats trouv√©s")

    # Stats
    stats = memory.get_memory_stats()
    print(f"Stats: {stats}")
